import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random as rn
------------------------------------------------------------------------------------
dataset1 = pd.read_csv('AirQuality.csv', sep = ";")
dataset2 = pd.read_csv('heart.csv')
------------------------------------------------------------------------------------
dataset1.head()
------------------------------------------------------------------------------------
dataset2.head()
------------------------------------------------------------------------------------
dataset1.info()
------------------------------------------------------------------------------------
Data Cleaning
# To check for missing values in the entire dataset:
dataset1.isnull()
------------------------------------------------------------------------------------
# To check the sum of null values in columns
dataset1.isnull().sum()
------------------------------------------------------------------------------------
# To drop rows with missing values
dataset1.dropna()
------------------------------------------------------------------------------------
# Removing duplicates
dataset1.drop_duplicates()
------------------------------------------------------------------------------------
#Data Integration
integration1 = dataset1.loc[111:999, ['Date', 'Time', 'C6H6(GT)', 'RH']]
------------------------------------------------------------------------------------
integration2 = dataset1.iloc[[1,3,5,2,4,22,43,54,67,7,8,9,50,10,11]]
------------------------------------------------------------------------------------
dataset1_integration = pd.concat([integration1, integration2])
------------------------------------------------------------------------------------
dataset1_integration
------------------------------------------------------------------------------------
# Data Transformation
dataset1_integration.transpose()
------------------------------------------------------------------------------------
dataset1.drop(columns = "NOx(GT)")
------------------------------------------------------------------------------------
dataset1.drop(1)
------------------------------------------------------------------------------------
# Data Transformation Error Correcting
dataset1
------------------------------------------------------------------------------------
# data transformation and error correcting
dataset1.rename(columns={'T':'Temperature','RH':'Humidity'},inplace=True)
dataset1.head()
------------------------------------------------------------------------------------
dataset1['Datetime'] = dataset1['Date'] + dataset1['Time']
dataset1.set_index('Datetime',inplace=True)
dataset1.head()
------------------------------------------------------------------------------------
# data integration 
#making subset of air quality dataset to show data integration
air_subset1 = dataset1[['Date','Time','CO(GT)','PT08.S1(CO)','Temperature']]
air_subset2 = dataset1[['Temperature','Humidity','AH']]
------------------------------------------------------------------------------------
air_subset1.head()
------------------------------------------------------------------------------------
air_subset2.head()
------------------------------------------------------------------------------------
integrated_data = pd.merge(air_subset1,air_subset2,on='Temperature')
integrated_data.head()
------------------------------------------------------------------------------------
# data model building
dataset2.head()
------------------------------------------------------------------------------------
dataset2.isnull().sum()
------------------------------------------------------------------------------------
dataset2.info()
------------------------------------------------------------------------------------
y = dataset2[['target']]
x = dataset2.drop(y,axis = 1)
y.head(2)
------------------------------------------------------------------------------------
y['target'].value_counts()
------------------------------------------------------------------------------------
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
------------------------------------------------------------------------------------
x_train.shape,x_test.shape,y_train.shape,y_test.shape
------------------------------------------------------------------------------------
from sklearn.linear_model import LogisticRegression
------------------------------------------------------------------------------------
lr=LogisticRegression()
------------------------------------------------------------------------------------
#predecting on test data
model = LogisticRegression()
model = LogisticRegression(max_iter=1000) 
model.fit(x_train, y_train)
y_test['Prediction'] = model.predict(x_test)
